# llama can only be used with a big GPU
*sci-misc/llama-cpp
